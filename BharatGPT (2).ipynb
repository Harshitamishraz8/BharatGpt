{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community chromadb fastapi uvicorn gTTS transformers accelerate llama-cpp-python\n",
        "# If you want GPU support for llama-cpp-python\n",
        "# !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121"
      ],
      "metadata": {
        "id": "JKwQUQ_t4uCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# --- LLM Model Configuration ---\n",
        "# This is the corrected repo ID and filename for OpenHathi-7B-Hi-v0.1-Base GGUF\n",
        "repo_id = \"sarvamai/OpenHathi-7B-Hi-v0.1-Base\"\n",
        "filename = \"OpenHathi-7B-Hi-v0.1-Base-q4_0.gguf\" # This is a specific GGUF file within that repo\n",
        "\n",
        "# Create a directory for models\n",
        "model_dir = \"./models\"\n",
        "os.makedirs(model_dir, exist_ok=True) # Ensure models directory exists\n",
        "\n",
        "LLM_MODEL_PATH = os.path.join(model_dir, filename)\n",
        "\n",
        "if not os.path.exists(LLM_MODEL_PATH):\n",
        "    print(f\"Downloading {filename} from {repo_id}...\")\n",
        "    try:\n",
        "        hf_hub_download(repo_id=repo_id, filename=filename, local_dir=model_dir, local_dir_use_symlinks=False)\n",
        "        print(\"Download complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading model: {e}\")\n",
        "        print(\"Please ensure the repo_id and filename are correct and you have access if it's a gated model.\")\n",
        "        print(\"If it's a gated model, make sure you've accepted the terms on its Hugging Face page and set your HF_TOKEN in Colab secrets.\")\n",
        "else:\n",
        "    print(f\"Model already exists at {LLM_MODEL_PATH}\")\n",
        "\n",
        "# --- Directory Setup for Static Files and ChromaDB ---\n",
        "# Ensure the 'static' directory exists before FastAPI tries to mount it\n",
        "os.makedirs(\"static\", exist_ok=True)\n",
        "print(\"Created 'static' directory for audio files.\")\n",
        "\n",
        "# Path for ChromaDB persistence\n",
        "# You can change this to a Google Drive path if you want persistence across sessions:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# CHROMA_DB_PATH = \"/content/drive/MyDrive/my_msme_bot_data/chroma_db\"\n",
        "CHROMA_DB_PATH = \"./chroma_db\"\n",
        "os.makedirs(CHROMA_DB_PATH, exist_ok=True) # Ensure ChromaDB directory exists\n",
        "print(f\"ChromaDB persistence directory set to: {CHROMA_DB_PATH}\")"
      ],
      "metadata": {
        "id": "eF5WnDoR47_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Form\n",
        "from fastapi.responses import HTMLResponse, FileResponse\n",
        "from typing import List, Dict\n",
        "import os\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# TTS imports\n",
        "from gtts import gTTS\n",
        "\n",
        "# --- FastAPI App Definition ---\n",
        "app = FastAPI()\n",
        "\n",
        "# --- Initialize LangChain Components (Singleton Pattern) ---\n",
        "# Global variables to store initialized components\n",
        "qa_chain = None\n",
        "embeddings_model = None\n",
        "vector_store = None\n",
        "llm_model = None\n",
        "\n",
        "def initialize_langchain():\n",
        "    global qa_chain, embeddings_model, vector_store, llm_model\n",
        "\n",
        "    if qa_chain is not None:\n",
        "        print(\"LangChain components already initialized.\")\n",
        "        return # Already initialized\n",
        "\n",
        "    print(\"Initializing LangChain components for the first time...\")\n",
        "\n",
        "    # 1. Embeddings Model\n",
        "    print(\"Loading Embeddings Model...\")\n",
        "    embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "    print(\"Embeddings Model Loaded.\")\n",
        "\n",
        "    # 2. Vector Store (ChromaDB)\n",
        "    # The directory creation is handled in Cell 2, ensuring it exists before this\n",
        "    print(f\"Loading/Creating ChromaDB at {CHROMA_DB_PATH}...\")\n",
        "    vector_store = Chroma(\n",
        "        embedding_function=embeddings_model,\n",
        "        persist_directory=CHROMA_DB_PATH\n",
        "    )\n",
        "    print(f\"ChromaDB initialized. Documents currently in store: {vector_store._collection.count()}\")\n",
        "\n",
        "    # Add some initial documents if the collection is empty (for demo)\n",
        "    if vector_store._collection.count() == 0:\n",
        "        print(\"Adding initial Hindi documents to ChromaDB...\")\n",
        "        sample_docs_hindi = [\n",
        "            \"सूक्ष्म, लघु और मध्यम उद्यम (MSME) भारत की अर्थव्यवस्था की रीढ़ हैं। सरकार MSME को बढ़ावा देने के लिए कई योजनाएं चला रही है, जैसे मुद्रा योजना और स्टैंड-अप इंडिया योजना।\",\n",
        "            \"मुद्रा योजना छोटे व्यवसायों को ₹10 लाख तक का ऋण प्रदान करती है ताकि वे अपने व्यापार का विस्तार कर सकें या नया व्यवसाय शुरू कर सकें।\",\n",
        "            \"पंजीकरण के लिए, आपको उद्योग आधार पोर्टल पर ऑनलाइन आवेदन करना होगा। यह प्रक्रिया सरल और मुफ्त है।\",\n",
        "            \"अपने व्यवसाय के लिए मार्केटिंग अभियान बनाने के लिए, आप लक्षित दर्शकों, संदेश और बजट को परिभाषित कर सकते हैं। सोशल मीडिया मार्केटिंग छोटे व्यवसायों के लिए बहुत प्रभावी हो सकती है।\",\n",
        "            \"स्टैंड-अप इंडिया योजना महिला उद्यमियों और अनुसूचित जाति/जनजाति के उद्यमियों को ₹10 लाख से ₹1 करोड़ तक का ऋण प्रदान करती है ताकि वे ग्रीनफ़ील्ड उद्यम स्थापित कर सकें।\",\n",
        "            \"एक प्रभावी विज्ञापन बनाने के लिए, आपको अपने उत्पाद या सेवा के मुख्य लाभों पर ध्यान केंद्रित करना चाहिए और एक स्पष्ट कॉल-टू-एक्शन शामिल करना चाहिए।\"\n",
        "        ]\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "        docs = text_splitter.create_documents(sample_docs_hindi)\n",
        "        vector_store.add_documents(docs)\n",
        "        print(\"Initial documents added.\")\n",
        "        vector_store.persist() # Important: Persist the database after adding documents\n",
        "        print(\"ChromaDB persisted with initial documents.\")\n",
        "    else:\n",
        "        print(\"ChromaDB already contains documents, skipping initial addition.\")\n",
        "\n",
        "    # 3. LLM (Large Language Model)\n",
        "    # LLM_MODEL_PATH is defined in Cell 2\n",
        "    print(f\"Attempting to load LLM from: {LLM_MODEL_PATH}\")\n",
        "    if not os.path.exists(LLM_MODEL_PATH):\n",
        "         print(f\"WARNING: LLM model not found at {LLM_MODEL_PATH}. Using a dummy LLM for basic responses.\")\n",
        "         class DummyLLM:\n",
        "             def invoke(self, prompt):\n",
        "                 print(f\"Dummy LLM received prompt: {prompt[:100]}...\")\n",
        "                 if \"मुद्रा योजना\" in prompt:\n",
        "                     return \"मुद्रा योजना छोटे व्यवसायों को ₹10 लाख तक का ऋण देती है ताकि वे अपना व्यवसाय शुरू या विस्तार कर सकें।\"\n",
        "                 elif \"पंजीकरण\" in prompt:\n",
        "                     return \"व्यवसाय पंजीकरण के लिए, आपको उद्योग आधार पोर्टल पर ऑनलाइन आवेदन करना होगा। यह प्रक्रिया सरल और मुफ्त है।\"\n",
        "                 elif \"मार्केटिंग\" in prompt:\n",
        "                     return \"मार्केटिंग के लिए सोशल मीडिया, लक्षित विज्ञापन और ग्राहक संबंध बनाना अच्छे तरीके हैं।\"\n",
        "                 elif \"अभियान\" in prompt and \"उत्पाद\" in prompt:\n",
        "                     # Dummy response for campaign generation\n",
        "                     if \"छूट\" in prompt and \"वैधता\" in prompt:\n",
        "                         return f\"आपके '{prompt.split('उत्पाद/सेवा: ')[1].splitlines()[0]}' उत्पाद पर '{prompt.split('छूट: ')[1].splitlines()[0]}' की शानदार छूट! यह ऑफर केवल '{prompt.split('वैधता: ')[1].splitlines()[0]}' तक वैध है। आज ही लाभ उठाएं!\"\n",
        "                     return f\"आपके '{prompt.split('उत्पाद/सेवा: ')[1].splitlines()[0]}' उत्पाद के लिए एक शानदार अभियान!\"\n",
        "                 return \"मुझे इस प्रश्न का उत्तर नहीं मिल रहा है। कृपया अधिक जानकारी के लिए पूछें।\"\n",
        "         llm_model = DummyLLM()\n",
        "    else:\n",
        "        try:\n",
        "            llm_model = LlamaCpp(\n",
        "                model_path=LLM_MODEL_PATH,\n",
        "                temperature=0.7,\n",
        "                max_tokens=500,\n",
        "                n_gpu_layers=0, # Set to 0 for CPU inference. Set > 0 (e.g., -1 for all) if you installed with CUDA support and have a GPU.\n",
        "                n_batch=512,\n",
        "                f16_kv=True,\n",
        "                verbose=False,\n",
        "                n_ctx=2048 # Context window size, match model capabilities\n",
        "            )\n",
        "            print(\"LlamaCpp LLM loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading LlamaCpp model from {LLM_MODEL_PATH}: {e}\")\n",
        "            print(\"Falling back to Dummy LLM. Please check your LlamaCpp installation and model file.\")\n",
        "            class DummyLLM:\n",
        "                 def invoke(self, prompt):\n",
        "                     print(f\"Dummy LLM received prompt: {prompt[:100]}...\")\n",
        "                     if \"मुद्रा योजना\" in prompt:\n",
        "                         return \"मुद्रा योजना छोटे व्यवसायों को ₹10 लाख तक का ऋण देती है ताकि वे अपना व्यवसाय शुरू या विस्तार कर सकें।\"\n",
        "                     elif \"पंजीकरण\" in prompt:\n",
        "                         return \"व्यवसाय पंजीकरण के लिए, आपको उद्योग आधार पोर्टल पर ऑनलाइन आवेदन करना होगा। यह प्रक्रिया सरल और मुफ्त है।\"\n",
        "                     elif \"मार्केटिंग\" in prompt:\n",
        "                         return \"मार्केटिंग के लिए सोशल मीडिया, लक्षित विज्ञापन और ग्राहक संबंध बनाना अच्छे तरीके हैं।\"\n",
        "                     elif \"अभियान\" in prompt and \"उत्पाद\" in prompt:\n",
        "                         if \"छूट\" in prompt and \"वैधता\" in prompt:\n",
        "                             return f\"आपके '{prompt.split('उत्पाद/सेवा: ')[1].splitlines()[0]}' उत्पाद पर '{prompt.split('छूट: ')[1].splitlines()[0]}' की शानदार छूट! यह ऑफर केवल '{prompt.split('वैधता: ')[1].splitlines()[0]}' तक वैध है। आज ही लाभ उठाएं!\"\n",
        "                         return f\"आपके '{prompt.split('उत्पाद/सेवा: ')[1].splitlines()[0]}' उत्पाद के लिए एक शानदार अभियान!\"\n",
        "                     return \"मुझे इस प्रश्न का उत्तर नहीं मिल रहा है। कृपया अधिक जानकारी के लिए पूछें।\"\n",
        "            llm_model = DummyLLM()\n",
        "\n",
        "\n",
        "    # 4. RAG Chain\n",
        "    print(\"Setting up RetrievalQA Chain...\")\n",
        "    prompt_template_hindi = \"\"\"आप एक हिंदी भाषी सहायक हैं जो भारतीय सूक्ष्म, लघु और मध्यम उद्यमों (MSME) की सहायता के लिए डिज़ाइन किए गए हैं।\n",
        "    दिए गए संदर्भ से ही उत्तर दें। यदि उत्तर संदर्भ में नहीं है, तो बस कहें कि \"मुझे इस प्रश्न का उत्तर नहीं मिल रहा है।\"\n",
        "    किसी भी तरह से कोई भी गलत जानकारी न दें।\n",
        "\n",
        "    संदर्भ:\n",
        "    {context}\n",
        "\n",
        "    प्रश्न: {question}\n",
        "    उत्तर:\"\"\"\n",
        "    PROMPT = PromptTemplate(template=prompt_template_hindi, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm_model,\n",
        "        chain_type=\"stuff\", # Simple stuffing of context into prompt\n",
        "        retriever=vector_store.as_retriever(),\n",
        "        return_source_documents=True, # Optional: to show what documents were used\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    print(\"LangChain components initialized successfully.\")\n",
        "\n",
        "# --- API Endpoints ---\n",
        "# Using lifespan context manager for FastAPI startup/shutdown events\n",
        "# This replaces the deprecated @app.on_event(\"startup\")\n",
        "from contextlib import asynccontextmanager\n",
        "\n",
        "@asynccontextmanager\n",
        "async def lifespan(app: FastAPI):\n",
        "    # This code runs on startup\n",
        "    initialize_langchain()\n",
        "    yield\n",
        "    # This code would run on shutdown (if needed)\n",
        "    print(\"FastAPI app shutting down.\")\n",
        "\n",
        "app = FastAPI(lifespan=lifespan) # Pass the lifespan to the FastAPI app\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def read_root():\n",
        "    # Simple HTML interface for the prototype\n",
        "    return \"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>BharatGPT MSME Bot Prototype</title>\n",
        "        <style>\n",
        "            body { font-family: Arial, sans-serif; margin: 40px; background-color: #f4f4f4; }\n",
        "            .container { background-color: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); max-width: 800px; margin: auto; }\n",
        "            input[type=\"text\"] { width: calc(100% - 100px); padding: 10px; margin-bottom: 10px; border: 1px solid #ddd; border-radius: 4px; }\n",
        "            button { padding: 10px 15px; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }\n",
        "            button:hover { background-color: #0056b3; }\n",
        "            #chat-output { border: 1px solid #eee; padding: 15px; min-height: 200px; max-height: 400px; overflow-y: auto; background-color: #f9f9f9; border-radius: 4px; margin-top: 20px; }\n",
        "            .message { margin-bottom: 10px; }\n",
        "            .user-message { text-align: right; color: #007bff; }\n",
        "            .bot-message { text-align: left; color: #333; }\n",
        "            audio { width: 100%; margin-top: 10px; }\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"container\">\n",
        "            <h1>BharatGPT MSME Bot (Prototype)</h1>\n",
        "            <p>Ask questions related to MSMEs in Hindi (e.g., मुद्रा योजना, पंजीकरण कैसे करें, मार्केटिंग).</p>\n",
        "\n",
        "            <div id=\"chat-output\"></div>\n",
        "\n",
        "            <form id=\"chat-form\">\n",
        "                <input type=\"text\" id=\"user-input\" placeholder=\"अपना प्रश्न हिंदी में टाइप करें...\" autocomplete=\"off\">\n",
        "                <button type=\"submit\">पूछें</button>\n",
        "                <button type=\"button\" id=\"campaign-button\">अभियान बनाएं</button>\n",
        "            </form>\n",
        "\n",
        "            <h2>अभियान बनाएं (Prototype)</h2>\n",
        "            <form id=\"campaign-form\">\n",
        "                <input type=\"text\" id=\"campaign-product\" placeholder=\"उत्पाद का नाम\" required>\n",
        "                <input type=\"text\" id=\"campaign-discount\" placeholder=\"छूट प्रतिशत (उदा. 10%)\">\n",
        "                <input type=\"text\" id=\"campaign-validity\" placeholder=\"वैधता (उदा. 31 जुलाई तक)\">\n",
        "                <button type=\"submit\">अभियान टेक्स्ट जनरेट करें</button>\n",
        "            </form>\n",
        "            <div id=\"campaign-output\" style=\"margin-top: 15px; border: 1px dashed #ccc; padding: 10px; min-height: 50px;\"></div>\n",
        "\n",
        "        </div>\n",
        "\n",
        "        <script>\n",
        "            const chatForm = document.getElementById('chat-form');\n",
        "            const userInput = document.getElementById('user-input');\n",
        "            const chatOutput = document.getElementById('chat-output');\n",
        "            const campaignButton = document.getElementById('campaign-button');\n",
        "            const campaignForm = document.getElementById('campaign-form');\n",
        "            const campaignProductInput = document.getElementById('campaign-product');\n",
        "            const campaignDiscountInput = document.getElementById('campaign-discount');\n",
        "            const campaignValidityInput = document.getElementById('campaign-validity');\n",
        "            const campaignOutput = document.getElementById('campaign-output');\n",
        "\n",
        "            async function sendMessage(message) {\n",
        "                const userMsgDiv = document.createElement('div');\n",
        "                userMsgDiv.className = 'message user-message';\n",
        "                userMsgDiv.textContent = `आप: ${message}`;\n",
        "                chatOutput.appendChild(userMsgDiv);\n",
        "                userInput.value = '';\n",
        "                chatOutput.scrollTop = chatOutput.scrollHeight; // Scroll to bottom\n",
        "\n",
        "                const response = await fetch('/chat', {\n",
        "                    method: 'POST',\n",
        "                    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },\n",
        "                    body: `query=${encodeURIComponent(message)}`\n",
        "                });\n",
        "                const data = await response.json();\n",
        "\n",
        "                const botMsgDiv = document.createElement('div');\n",
        "                botMsgDiv.className = 'message bot-message';\n",
        "                botMsgDiv.textContent = `बॉट: ${data.response}`;\n",
        "                chatOutput.appendChild(botMsgDiv);\n",
        "\n",
        "                if (data.audio_url) {\n",
        "                    const audio = document.createElement('audio');\n",
        "                    audio.controls = true;\n",
        "                    audio.src = data.audio_url;\n",
        "                    botMsgDiv.appendChild(audio);\n",
        "                    audio.play(); // Auto-play\n",
        "                }\n",
        "                chatOutput.scrollTop = chatOutput.scrollHeight; // Scroll to bottom again\n",
        "            }\n",
        "\n",
        "            async function generateCampaign(product, discount, validity) {\n",
        "                campaignOutput.innerHTML = 'जनरेट कर रहा है...';\n",
        "                const response = await fetch('/generate_campaign', {\n",
        "                    method: 'POST',\n",
        "                    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },\n",
        "                    body: `product=${encodeURIComponent(product)}&discount=${encodeURIComponent(discount)}&validity=${encodeURIComponent(validity)}`\n",
        "                });\n",
        "                const data = await response.json();\n",
        "                campaignOutput.textContent = data.campaign_text;\n",
        "            }\n",
        "\n",
        "\n",
        "            chatForm.addEventListener('submit', (e) => {\n",
        "                e.preventDefault();\n",
        "                const message = userInput.value.trim();\n",
        "                if (message) {\n",
        "                    sendMessage(message);\n",
        "                }\n",
        "            });\n",
        "\n",
        "            campaignForm.addEventListener('submit', (e) => {\n",
        "                e.preventDefault();\n",
        "                const product = campaignProductInput.value.trim();\n",
        "                const discount = campaignDiscountInput.value.trim();\n",
        "                const validity = campaignValidityInput.value.trim();\n",
        "                if (product) {\n",
        "                    generateCampaign(product, discount, validity);\n",
        "                } else {\n",
        "                    alert('कृपया उत्पाद का नाम दर्ज करें।');\n",
        "                }\n",
        "            });\n",
        "\n",
        "            window.onload = () => {\n",
        "                const welcomeDiv = document.createElement('div');\n",
        "                welcomeDiv.className = 'message bot-message';\n",
        "                welcomeDiv.textContent = 'बॉट: नमस्कार! मैं भारतजीपीटी एमएसएमई बॉट का प्रोटोटाइप हूँ। मैं आपकी कैसे मदद कर सकता हूँ?';\n",
        "                chatOutput.appendChild(welcomeDiv);\n",
        "            };\n",
        "\n",
        "        </script>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def chat_endpoint(query: str = Form(...)):\n",
        "    # Main RAG logic\n",
        "    # initialize_langchain() is called by the lifespan event\n",
        "    if qa_chain is None: # Fallback check, theoretically should be initialized by lifespan\n",
        "         return {\"response\": \"बॉट अभी तैयार नहीं है। कृपया कुछ देर प्रतीक्षा करें या LLM मॉडल पाथ जांचें।\", \"audio_url\": None}\n",
        "\n",
        "    print(f\"Received query: {query}\")\n",
        "    try:\n",
        "        result = qa_chain.invoke({\"query\": query})\n",
        "        bot_response = result.get(\"result\", \"मुझे इस प्रश्न का उत्तर नहीं मिल रहा है।\")\n",
        "        print(f\"Bot response: {bot_response}\")\n",
        "\n",
        "        # Generate TTS audio\n",
        "        audio_filename = f\"audio_{hash(bot_response)}.mp3\" # Simple hash for unique name\n",
        "        audio_path = os.path.join(\"static\", audio_filename)\n",
        "        # os.makedirs(\"static\", exist_ok=True) # This is already handled in Cell 2\n",
        "        try:\n",
        "            tts = gTTS(text=bot_response, lang='hi', slow=False)\n",
        "            tts.save(audio_path)\n",
        "            audio_url = f\"/static/{audio_filename}\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating TTS: {e}\")\n",
        "            audio_url = None\n",
        "\n",
        "        return {\"response\": bot_response, \"audio_url\": audio_url}\n",
        "    except Exception as e:\n",
        "        print(f\"Error during chat processing: {e}\")\n",
        "        return {\"response\": \"क्षमा करें, कुछ त्रुटि हुई।\", \"audio_url\": None}\n",
        "\n",
        "@app.post(\"/generate_campaign\")\n",
        "async def generate_campaign_endpoint(\n",
        "    product: str = Form(...),\n",
        "    discount: str = Form(\"\"),\n",
        "    validity: str = Form(\"\")\n",
        "):\n",
        "    # initialize_langchain() is called by the lifespan event\n",
        "    if llm_model is None: # Fallback check\n",
        "         return {\"campaign_text\": \"बॉट अभी तैयार नहीं है। कृपया कुछ देर प्रतीक्षा करें या LLM मॉडल पाथ जांचें।\"}\n",
        "\n",
        "    campaign_prompt = f\"\"\"एक छोटे व्यवसाय के लिए एक आकर्षक हिंदी मार्केटिंग अभियान टेक्स्ट जनरेट करें।\n",
        "    उत्पाद/सेवा: {product}\n",
        "    \"\"\"\n",
        "    if discount:\n",
        "        campaign_prompt += f\"छूट: {discount}\\n\"\n",
        "    if validity:\n",
        "        campaign_prompt += f\"वैधता: {validity}\\n\"\n",
        "\n",
        "    campaign_prompt += \"\"\"\n",
        "    अभियान टेक्स्ट:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        campaign_text = llm_model.invoke(campaign_prompt)\n",
        "        # Simple cleanup, LLMs can sometimes add extra text or conversational turns\n",
        "        # This tries to extract the pure campaign text\n",
        "        if \"अभियान टेक्स्ट:\" in campaign_text:\n",
        "            campaign_text = campaign_text.split(\"अभियान टेक्स्ट:\")[-1].strip()\n",
        "        # Further refine if it includes conversational filler\n",
        "        if campaign_text.lower().startswith((\"यहां एक अभियान टेक्स्ट है:\", \"यहाँ एक अभियान टेक्स्ट है:\", \"यह रहा आपका अभियान:\", \"आपका अभियान टेक्स्ट यहाँ है:\", \"निश्चित रूप से, यहाँ है:\")):\n",
        "            campaign_text = campaign_text.split(\":\", 1)[-1].strip()\n",
        "\n",
        "        return {\"campaign_text\": campaign_text}\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating campaign: {e}\")\n",
        "        return {\"campaign_text\": \"अभियान टेक्स्ट जनरेट करने में त्रुटि हुई।\"}\n",
        "\n",
        "# To serve static files (like audio)\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")"
      ],
      "metadata": {
        "id": "TeuybZRJ4_yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import os\n",
        "\n",
        "# Apply nest_asyncio for running FastAPI inside a Jupyter environment\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set your ngrok authtoken from Colab secrets\n",
        "# Go to the left sidebar in Colab, click the key icon (Secrets), and add a new secret.\n",
        "# Name: NGROK_AUTH_TOKEN, Value: <Your_Ngrok_Token_Here>\n",
        "try:\n",
        "    NGROK_AUTH_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "        print(\"ngrok authtoken set from Colab secrets.\")\n",
        "    else:\n",
        "        print(\"WARNING: NGROK_AUTH_TOKEN not found in Colab secrets. ngrok might ask for it or limit usage.\")\n",
        "        print(\"Please add your ngrok token to Colab secrets for stable operation.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error setting ngrok authtoken: {e}\")\n",
        "\n",
        "# Start ngrok tunnel on port 8000\n",
        "print(\"Starting ngrok tunnel...\")\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print(f\"Public URL: {public_url}\")\n",
        "print(\"Open this URL in your browser to access the bot.\")\n",
        "\n",
        "# Run your FastAPI app using uvicorn within the same cell\n",
        "# This will block the cell, but your FastAPI app will be accessible via the public_url\n",
        "import uvicorn\n",
        "print(\"Starting Uvicorn server...\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "_w0zEBbs63Ev"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}